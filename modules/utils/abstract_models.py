import numpy as np


class _AbstractAutoencoder:
    """Private class storing utility methods inherited by Autoencoders
    """
    def fit(self, X_train, epochs, batch_size, noise=None, **kwargs):
        """Method for fitting the encoder_decoder model and saving the entire
        architecture as well as the encoder, decoder parts

        Args:
            - X_train:      is a numpy array storing the values passed to the
                            encoder_decoder
            - epochs:       is an integer specifyinng for how many number of
                            epochs the model will be trained
            - batch_size:   is a float and specifying the ratio of X_train
                            over which the error is computed

        Returns:
            - None
        """
        if noise is not None:
            X_target = X_train + np.random.normal(0, noise, size=X_train.shape)
        else:
            X_target = X_train
        self._encoder_decoder.fit(
            X_train,
            X_target,
            epochs=epochs,
            batch_size=batch_size,
            **kwargs
        )
        return self._encoder_decoder, self._encoder

    def encode_decode(self, X_test):
        """Method for transforming and reducing an input to size of the latent
        space of the encoder and then back to the original input, this can be
        use for value inputation in case of corrupted entries

        Args:
            - X_test:   is a numpy array storing the values that needs
                        to be transformed

        Returns:
            - a numpy array storing the values for the transformation of X_test
        """
        return self._encoder_decoder.predict(X_test)

    def encode(self, X_test):
        """Method for transforming and reducing an input to size of the latent
        space of the encoder

        Args:
            - X_test:   is a numpy array storing the values that needs
                        to be transformed

        Returns:
            - a numpy array storing the values for the transformation of X_test
        """
        return self._encoder.predict(X_test)

    def get_model(self):
        """
        """
        model = self._encoder_decoder
        return model

    def get_model_tag(self):
        """Method for getting the model tag (identifier)

        Returns:
            -model_tag: a string specifying the model tag
        """
        model_tag = self.model_tag
        return model_tag


class _AbstractDEC:
    """Private class implementing methods inherited by the actual DEC models
    """
    def _print_status(self, status):
        """Protected method for printing the status of the training process

        Args:
            - status: is a dictionary, keys are logs to keep track of values
              are the metric associated to the logs

        Return:
            - None
        """
        for key, value in status.items():

            print('{}: {}'.format(key, value))

    def _generate_target_distribution(self, q):
        """Protected method for generating the target distribution of cluster
        assignments for the clustering layer. The target distribution is
        computed from the probabilistic assignment generated by the clustering
        layer every update_interval iterations, It is therefore a form of
        self learning.

        Args:
            - q: a keras tensor, soft label assignements of shape
                 (samples, n_labels) produced by the t-student distribution.

        Returns:
            - p: a keras tensor, target distribution generated from the soft
                 assignement.
        """
        weight = q ** 2 / q.sum(0)
        p = (weight.T / weight.sum(1)).T
        return p

    def get_model(self):
        model = self._model
        return model

    def set_model(self, model):
        setattr(self, '_model', model)
        setattr(self, 'n_parameters', model.count_params())

    def get_model_tag(self):
        model_tag = self.model_tag
        return model_tag
